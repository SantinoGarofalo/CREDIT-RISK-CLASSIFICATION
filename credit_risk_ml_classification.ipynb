{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOlRR53QU40fYsX6qpobsBg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SantinoGarofalo/CREDIT-RISK-CLASSIFICATION/blob/main/credit_risk_ml_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Sviluppo Pipeline di Machine Learning : GERMAN CREDIT DATASET**"
      ],
      "metadata": {
        "id": "mkNRLCaYxwky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Credit Scoring su German Credit Dataset  \n",
        "### Valutazione del rischio di credito: Good vs Bad Payers\n",
        "\n",
        "In questo notebook sviluppiamo una **pipeline end-to-end di Machine Learning** per supportare il processo di **credit scoring**: dato il profilo di un cliente, stimiamo la probabilità che sia un:\n",
        "\n",
        "- **Good Payer** → Basso rischio di insolvenza  \n",
        "- **Bad Payer** → Alto rischio di insolvenza  \n",
        "\n",
        "L’obiettivo non è solo raggiungere buone performance predittive, ma anche:\n",
        "\n",
        "- garantire una **valutazione robusta e affidabile** (train/valid/test, CV stratificata, tuning iperparametri)\n",
        "- mantenere **interpretabilità ed explainability** (Feature Importance, SHAP, LIME, PDP/ICE)\n",
        "- collegare i risultati a una **logica di business** (trade-off tra precision/recall sui Bad Payers).\n"
      ],
      "metadata": {
        "id": "6QIpoFFP4XcS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Executive Summary\n",
        "\n",
        "Gli istituti finanziari devono decidere se **concedere o meno un credito** a un potenziale cliente.  \n",
        "Una decisione errata può comportare:\n",
        "\n",
        "- **False Negative (Bad Payer classificato come Good)** → perdita economica potenzialmente significativa  \n",
        "- **False Positive (Good Payer classificato come Bad)** → mancato guadagno e peggioramento della customer experience  \n",
        "\n",
        "In questo lavoro:\n",
        "\n",
        "- costruiamo un **classificatore binario** su un dataset storico di clienti (German Credit Dataset, 1.000 osservazioni)\n",
        "- stimiamo il **rischio di insolvenza** e analizziamo l’impatto delle principali variabili (es. durata del credito, storico dei pagamenti, importo)\n",
        "- esploriamo il **trade-off fra recall e precision sui Bad Payers**, in funzione del profilo di rischio dell’istituto.\n"
      ],
      "metadata": {
        "id": "pdFuvF0R4kdz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Struttura del Notebook\n",
        "\n",
        "1. [Executive Summary](#1-Executive-Summary)  \n",
        "2. [Struttura del Notebook](#2-Struttura-del-Notebook)  \n",
        "3. [Setup Tecnico & Caricamento Dati](#3-Setup-Tecnico--Caricamento-Dati)  \n",
        "4. [Data Understanding & Data Quality](#4-Data-Understanding--Data-Quality)  \n",
        "5. [Data Engineering & Feature Engineering](#5-Data-Engineering--Feature-Engineering)  \n",
        "6. [Modellazione & Strategia di Validazione](#6-Modellazione--Strategia-di-Validazione)  \n",
        "7. [Model Selection & Hyperparameter Tuning](#7-Model-Selection--Hyperparameter-Tuning)  \n",
        "8. [Valutazione Finale su Test Set](#8-Valutazione-Finale-su-Test-Set)  \n",
        "9. [Explainability (XAI) & Risk Governance](#9-Explainability-XAI--Risk-Governance)  \n",
        "10. [Conclusioni & Next Steps](#10-Conclusioni--Next-Steps)  \n"
      ],
      "metadata": {
        "id": "RJoYdIIu4wFE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Setup Tecnico & Caricamento Dati\n",
        "\n",
        "In questa sezione:\n",
        "\n",
        "- importiamo le principali librerie per **data analysis** e **machine learning**\n",
        "- fissiamo alcuni **parametri globali** (es. `RANDOM_STATE`)\n",
        "- carichiamo il **German Credit Dataset** da `openml` e definiamo la variabile target.\n"
      ],
      "metadata": {
        "id": "w0KzbOi85BI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurazione generale\n",
        "RANDOM_STATE = 42\n",
        "import warnings #libreria di warning\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Manipolazione dati\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Visualizzazione\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.style.use(\"default\")\n",
        "sns.set_theme()\n",
        "\n",
        "# Dataset\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, cross_validate\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Modelli\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, IsolationForest\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Metriche\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
        "    confusion_matrix, RocCurveDisplay, PrecisionRecallDisplay\n",
        ")\n",
        "!pip install xgboost lightgbm optuna shap lime --quiet\n",
        "\n",
        "# Explainability\n",
        "import shap\n",
        "from lime.lime_tabular import LimeTabularExplainer\n",
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "\n",
        "# Tuning\n",
        "import optuna\n"
      ],
      "metadata": {
        "id": "KO0k8PTI5FK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Caricamento German Credit Dataset da OpenML\n",
        "data = fetch_openml(\"credit-g\", version=1, as_frame=True)\n",
        "df_raw = data.frame.copy()\n",
        "\n",
        "print(f\"Shape originale del dataset: {df_raw.shape}\")\n",
        "display(df_raw.head())"
      ],
      "metadata": {
        "id": "S3ch3n7B5W9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Definizione della variabile target\n",
        "\n",
        "La variabile target nel German Credit Dataset è `class`, con due possibili valori:\n",
        "\n",
        "- `good` → cliente considerato affidabile\n",
        "- `bad` → cliente considerato rischioso  \n",
        "\n",
        "Per maggiore chiarezza business, la rinominiamo in **`Risk`** e la codifichiamo come:\n",
        "\n",
        "- `0` → Good Payer  \n",
        "- `1` → Bad Payer\n"
      ],
      "metadata": {
        "id": "W5FzzQCY5gsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copia di lavoro del dataset\n",
        "df = df_raw.rename(columns={\"class\": \"Risk\"}).copy()\n",
        "\n",
        "# Analisi rapida della distribuzione della target\n",
        "print(\"Distribuzione originale della variabile 'Risk':\")\n",
        "display(df[\"Risk\"].value_counts())\n",
        "display(df[\"Risk\"].value_counts(normalize=True).rename(\"proportion\"))\n",
        "\n",
        "# Codifica binaria: 1 = Bad Payer, 0 = Good Payer\n",
        "df[\"Risk_binary\"] = (df[\"Risk\"] == \"bad\").astype(int)\n",
        "df[[\"Risk\", \"Risk_binary\"]].head()"
      ],
      "metadata": {
        "id": "jSxcdTcS5hMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Data Understanding & Data Quality\n",
        "\n",
        "Obiettivo di questa sezione:\n",
        "\n",
        "- comprendere la **struttura del dataset** (tipologie di variabili, cardinalità, distribuzioni)\n",
        "- verificare la presenza di **missing values** e **anomalie evidenti**\n",
        "- analizzare il **bilanciamento della variabile target**, cruciale per problemi di credit scoring.\n"
      ],
      "metadata": {
        "id": "-kHUo0RX6Brh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tipologie di variabili\n",
        "print(\"Informazioni sulle colonne:\")\n",
        "df.info()\n",
        "\n",
        "# Missing values\n",
        "missing = df.isna().sum()\n",
        "missing = missing[missing > 0].sort_values(ascending=False)\n",
        "\n",
        "if missing.empty:\n",
        "    print(\"\\nNessun missing value rilevato nel dataset.\")\n",
        "else:\n",
        "    print(\"\\nMissing values per colonna:\")\n",
        "    display(missing.to_frame(name=\"n_missing\"))"
      ],
      "metadata": {
        "id": "qkjmfNi86CTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Qualità dei dati\n",
        "\n",
        "Dal check preliminare si osserva che:\n",
        "\n",
        "-  *“non sono presenti valori mancanti, il che semplifica la fase di data cleaning”*  \n",
        "- il dataset contiene sia **variabili numeriche** che **categoriche**, spesso codificate in forma stringa (es. stato del conto, scopo del credito, rating di credito precedente).\n",
        "\n",
        "Questi aspetti guideranno le scelte successive di:\n",
        "\n",
        "- **encoding** (One-Hot Encoding per le categoriche)\n",
        "- **scaling** (StandardScaler per le numeriche)."
      ],
      "metadata": {
        "id": "R03gyPBB81kI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identificazione feature numeriche e categoriche (escludiamo la target binaria)\n",
        "feature_cols = [c for c in df.columns if c not in [\"Risk\", \"Risk_binary\"]]\n",
        "\n",
        "numeric_features = df[feature_cols].select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_features = df[feature_cols].select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
        "\n",
        "print(\"Feature numeriche:\", numeric_features)\n",
        "print(\"Feature categoriche:\", categorical_features)"
      ],
      "metadata": {
        "id": "mALfmsGH82ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(4,4))\n",
        "sns.countplot(x=\"Risk\", data=df, ax=ax)\n",
        "ax.set_title(\"Distribuzione della variabile target (Good vs Bad)\")\n",
        "ax.set_xlabel(\"Risk\")\n",
        "ax.set_ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JSuGFOmx9YjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Bilanciamento della variabile target\n",
        "\n",
        "La distribuzione di `Risk` è **sbilanciata**:\n",
        "\n",
        "- la maggior parte dei clienti è classificata come **Good**\n",
        "- la classe **Bad** è meno frequente, ma non estremamente rara.\n",
        "\n",
        "Questo ha implicazioni importanti:\n",
        "\n",
        "- metriche come **accuracy** possono risultare fuorvianti  \n",
        "- saranno fondamentali **precision, recall, F1 e AUC**, con particolare attenzione alla **recall sulla classe Bad**  \n",
        "  (mancare un Bad Payer significa potenziale perdita economica)."
      ],
      "metadata": {
        "id": "MMFigBnr9gzq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Data Engineering & Feature Engineering\n",
        "\n",
        "In questa sezione applichiamo una serie di trasformazioni ai dati grezzi per renderli adatti alla modellazione:\n",
        "\n",
        "1. **Gestione outlier** sulle variabili numeriche, combinando:\n",
        "   - approccio **statistico** (Interquartile Range, IQR)\n",
        "   - approccio **model-based** (Isolation Forest)\n",
        "\n",
        "2. **Feature engineering mirata** per migliorare la capacità predittiva del modello.\n",
        "\n",
        "3. Definizione chiara dello **schema delle feature** (numeriche vs categoriche) da utilizzare nel preprocessing."
      ],
      "metadata": {
        "id": "0w_AS1lY94Ox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 Rilevamento e trattamento outlier\n",
        "\n",
        "Nel contesto di **credit scoring**, gli outlier possono rappresentare:\n",
        "\n",
        "- **casi realmente estremi** (es. importi molto elevati, durate particolari del credito)\n",
        "- **anomalie / errori** di registrazione\n",
        "\n",
        "In questo notebook adottiamo un approccio conservativo:\n",
        "\n",
        "- applichiamo una **doppia logica di rilevamento** sugli attributi numerici:\n",
        "  - IQR (Interquartile Range): individua valori molto distanti dalla massa dei dati\n",
        "  - Isolation Forest: modello unsupervised che isola osservazioni \"strane\"\n",
        "\n",
        "- rimuoviamo solo i record che risultano outlier **almeno secondo uno dei due metodi**, documentando l’impatto sul dataset.\n"
      ],
      "metadata": {
        "id": "-aBjpAiP-FE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_eng = df.copy() # Initialize df_eng by copying df\n",
        "\n",
        "# Riconfermiamo le feature numeriche / categoriche sulla copia df_eng\n",
        "feature_cols = [c for c in df_eng.columns if c not in [\"Risk\", \"Risk_binary\"]]\n",
        "\n",
        "numeric_features = df_eng[feature_cols].select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_features = df_eng[feature_cols].select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
        "\n",
        "print(\"Feature numeriche:\", numeric_features)\n",
        "print(\"Feature categoriche:\", categorical_features)\n",
        "\n",
        "\n",
        "def iqr_outlier_mask(df, cols, k=1.5):\n",
        "    \"\"\"\n",
        "    Restituisce una mask booleana degli outlier secondo regola IQR:\n",
        "    valori al di fuori di [Q1 - k*IQR, Q3 + k*IQR].\n",
        "    \"\"\"\n",
        "    mask = pd.Series(False, index=df.index)\n",
        "    for c in cols:\n",
        "        q1 = df[c].quantile(0.25)\n",
        "        q3 = df[c].quantile(0.75)\n",
        "        iqr = q3 - q1\n",
        "        lower = q1 - k * iqr\n",
        "        upper = q3 + k * iqr\n",
        "        mask = mask | (df[c] < lower) | (df[c] > upper)\n",
        "    return mask\n",
        "\n",
        "\n",
        "# Mask outlier con IQR\n",
        "iqr_mask = iqr_outlier_mask(df_eng, numeric_features)\n",
        "print(f\"Outlier rilevati con IQR: {iqr_mask.sum()} ({iqr_mask.mean():.2%} del dataset)\")\n",
        "\n",
        "# Mask outlier con Isolation Forest\n",
        "iso = IsolationForest(\n",
        "    contamination=0.05,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "iso_labels = iso.fit_predict(df_eng[numeric_features])\n",
        "iso_mask = (iso_labels == -1)\n",
        "print(f\"Outlier rilevati con Isolation Forest: {iso_mask.sum()} ({iso_mask.mean():.2%} del dataset)\")\n",
        "\n",
        "# Mask combinata (logica OR)\n",
        "combined_mask = iqr_mask | iso_mask\n",
        "print(f\"Outlier totali (IQR ∪ Isolation Forest): {combined_mask.sum()} ({combined_mask.mean():.2%} del dataset)\")"
      ],
      "metadata": {
        "id": "yUzV7wpO-F-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape iniziale: {df_eng.shape}\")\n",
        "df_clean = df_eng.loc[~combined_mask].reset_index(drop=True)\n",
        "print(f\"Shape dopo rimozione outlier: {df_clean.shape}\")\n",
        "\n",
        "print(\"\\nDistribuzione 'Risk_binary' dopo la pulizia:\")\n",
        "display(df_clean[\"Risk_binary\"].value_counts())\n",
        "display(df_clean[\"Risk_binary\"].value_counts(normalize=True).rename(\"proportion\"))"
      ],
      "metadata": {
        "id": "PL8NYJld-15g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Osservazioni sugli outlier**\n",
        "\n",
        "- La rimozione degli outlier comporta una riduzione del dataset del **27,20%**\n",
        "- La distribuzione della variabile target `Risk_binary` rimane **sostanzialmente stabile**, segno che non stiamo eliminando in modo selettivo una delle due classi.\n",
        "- In un contesto reale, questa scelta andrebbe discussa con il **risk management**:\n",
        "  - alcuni outlier potrebbero rappresentare **casi business rilevanti** (es. high-net-worth individuals)\n",
        "  - la logica di filtraggio potrebbe diventare una **regola di data quality** condivisa a livello aziendale."
      ],
      "metadata": {
        "id": "Ft_KnZqM_G5a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2 Feature Engineering\n",
        "\n",
        "Come esempio di feature engineering introduciamo una variabile binaria:\n",
        "\n",
        "- `long_duration`: vale 1 se la **durata del credito** è superiore alla mediana del campione.\n",
        "\n",
        "L’idea è catturare il fatto che **crediti più lunghi** possono essere associati a un profilo di rischio diverso, per via della maggiore incertezza sul futuro del cliente.\n"
      ],
      "metadata": {
        "id": "6SnuTuS3Z5fN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creazione feature binaria sulla durata del credito\n",
        "duration_median = df_clean[\"duration\"].median()\n",
        "df_clean[\"long_duration\"] = (df_clean[\"duration\"] > duration_median).astype(int)\n",
        "\n",
        "# Aggiorno la lista delle feature (escludo target)\n",
        "feature_cols_clean = [c for c in df_clean.columns if c not in [\"Risk\", \"Risk_binary\"]]\n",
        "\n",
        "numeric_features = df_clean[feature_cols_clean].select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_features = df_clean[feature_cols_clean].select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
        "\n",
        "print(\"Feature numeriche (post-feature engineering):\")\n",
        "print(numeric_features)\n",
        "print(\"\\nFeature categoriche (post-feature engineering):\")\n",
        "print(categorical_features)"
      ],
      "metadata": {
        "id": "5S7pm9W9_Hxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Modellazione & Strategia di Validazione\n",
        "\n",
        "Per costruire e valutare i modelli seguiamo questa strategia:\n",
        "\n",
        "- **Train (60%)**: usato per stimare i parametri dei modelli  \n",
        "- **Validation (20%)**: usato per confrontare modelli / soglie / configurazioni  \n",
        "- **Test (20%)**: usato solo alla fine per la valutazione definitiva\n",
        "\n",
        "Tutti gli split sono **stratificati sulla variabile `Risk_binary`** per preservare il rapporto Good / Bad.\n"
      ],
      "metadata": {
        "id": "XyyNQwFjaJTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrice delle feature e target\n",
        "X = df_clean[feature_cols_clean].copy()\n",
        "y = df_clean[\"Risk_binary\"].copy()\n",
        "\n",
        "# Train+Validation vs Test (80/20)\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.20,\n",
        "    stratify=y,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Train vs Validation (60/20 globale)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val,\n",
        "    test_size=0.25,\n",
        "    stratify=y_train_val,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "print(\"Shape Train     :\", X_train.shape)\n",
        "print(\"Shape Validation:\", X_val.shape)\n",
        "print(\"Shape Test      :\", X_test.shape)\n",
        "\n",
        "print(\"\\nDistribuzione target per split:\")\n",
        "for name, target in [(\"Train\", y_train), (\"Validation\", y_val), (\"Test\", y_test)]:\n",
        "    print(f\"\\n{name}\")\n",
        "    display(target.value_counts(normalize=True).rename(\"proportion\"))\n"
      ],
      "metadata": {
        "id": "yGDKPXptaA6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Preprocessing: encoding & scaling\n",
        "\n",
        "Definiamo un pipeline di preprocessing riutilizzabile in tutti i modelli:\n",
        "\n",
        "- **numeriche** → `StandardScaler`\n",
        "- **categoriche** → `OneHotEncoder(handle_unknown=\"ignore\")`\n",
        "\n",
        "Il tutto viene assemblato con `ColumnTransformer` e integrato nei modelli tramite `Pipeline`."
      ],
      "metadata": {
        "id": "blJG4Y-SafQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_transformer = Pipeline(steps=[\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_features),\n",
        "        (\"cat\", categorical_transformer, categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocessor"
      ],
      "metadata": {
        "id": "3M5ncg79aUli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2 Funzioni helper per metriche e cross-validation\n",
        "\n",
        "Definiamo ora alcune funzioni di utilità per:\n",
        "\n",
        "- stampare le metriche principali su un singolo set (Validation / Test)\n",
        "- eseguire una **cross-validation stratificata** con più metriche contemporaneamente."
      ],
      "metadata": {
        "id": "cfh48uObaua8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_classification_metrics(y_true, y_pred, y_proba, prefix=\"\"):\n",
        "    if prefix:\n",
        "        print(f\"=== {prefix} ===\")\n",
        "    print(f\"Accuracy : {accuracy_score(y_true, y_pred):.3f}\")\n",
        "    print(f\"Precision: {precision_score(y_true, y_pred):.3f}\")\n",
        "    print(f\"Recall   : {recall_score(y_true, y_pred):.3f}\")\n",
        "    print(f\"F1-score : {f1_score(y_true, y_pred):.3f}\")\n",
        "    print(f\"AUC      : {roc_auc_score(y_true, y_proba):.3f}\")\n",
        "\n",
        "\n",
        "scoring = {\n",
        "    \"accuracy\": \"accuracy\",\n",
        "    \"precision\": \"precision\",\n",
        "    \"recall\": \"recall\",\n",
        "    \"f1\": \"f1\",\n",
        "    \"roc_auc\": \"roc_auc\"\n",
        "}\n",
        "\n",
        "def evaluate_model_cv(model, X, y, cv=5, scoring=scoring, random_state=RANDOM_STATE):\n",
        "    skf = StratifiedKFold(\n",
        "        n_splits=cv,\n",
        "        shuffle=True,\n",
        "        random_state=random_state\n",
        "    )\n",
        "    cv_results = cross_validate(\n",
        "        model,\n",
        "        X,\n",
        "        y,\n",
        "        cv=skf,\n",
        "        scoring=scoring,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    summary = {\n",
        "        metric: {\n",
        "            \"mean\": cv_results[f\"test_{metric}\"].mean(),\n",
        "            \"std\": cv_results[f\"test_{metric}\"].std()\n",
        "        }\n",
        "        for metric in scoring.keys()\n",
        "    }\n",
        "    return summary\n"
      ],
      "metadata": {
        "id": "AArRT4unavGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Model Selection & Hyperparameter Tuning\n",
        "\n",
        "### 7.1 Modello baseline: Logistic Regression\n",
        "\n",
        "Come baseline utilizziamo una **Logistic Regression**:\n",
        "\n",
        "- è un modello lineare, semplice da interpretare\n",
        "- è ampiamente utilizzato in ambito **credit risk** (anche per motivi regolamentari)\n",
        "\n",
        "Tutti i modelli successivi dovranno portare un miglioramento rispetto a questa baseline, in particolare su:\n",
        "\n",
        "- **AUC**\n",
        "- **Recall sulla classe Bad (1)**."
      ],
      "metadata": {
        "id": "1WkX2HzXbIQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg_clf = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocessor),\n",
        "    (\"model\", LogisticRegression(\n",
        "        max_iter=1000,\n",
        "        class_weight=\"balanced\",   # per dare più peso alla classe minoritaria (Bad)\n",
        "        random_state=RANDOM_STATE\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Fit su Train\n",
        "log_reg_clf.fit(X_train, y_train)\n",
        "\n",
        "# Valutazione su Validation\n",
        "y_val_pred = log_reg_clf.predict(X_val)\n",
        "y_val_proba = log_reg_clf.predict_proba(X_val)[:, 1]\n",
        "\n",
        "print_classification_metrics(y_val, y_val_pred, y_val_proba, prefix=\"Logistic Regression - Validation\")"
      ],
      "metadata": {
        "id": "85Os_eJhbJGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {}\n",
        "\n",
        "# Logistic Regression (baseline) anche in CV\n",
        "models[\"LogisticRegression\"] = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocessor),\n",
        "    (\"model\", LogisticRegression(\n",
        "        max_iter=1000,\n",
        "        class_weight=\"balanced\",\n",
        "        random_state=RANDOM_STATE\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Random Forest\n",
        "models[\"RandomForest\"] = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocessor),\n",
        "    (\"model\", RandomForestClassifier(\n",
        "        n_estimators=300,\n",
        "        max_depth=None,\n",
        "        class_weight=\"balanced\",\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_jobs=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Gradient Boosting\n",
        "models[\"GradientBoosting\"] = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocessor),\n",
        "    (\"model\", GradientBoostingClassifier(\n",
        "        random_state=RANDOM_STATE\n",
        "    ))\n",
        "])\n",
        "\n",
        "# XGBoost\n",
        "models[\"XGBoost\"] = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocessor),\n",
        "    (\"model\", xgb.XGBClassifier(\n",
        "        objective=\"binary:logistic\",\n",
        "        eval_metric=\"logloss\",\n",
        "        n_estimators=300,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=4,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_jobs=-1\n",
        "    ))\n",
        "])\n",
        "\n",
        "# LightGBM\n",
        "models[\"LightGBM\"] = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocessor),\n",
        "    (\"model\", lgb.LGBMClassifier(\n",
        "        objective=\"binary\",\n",
        "        n_estimators=300,\n",
        "        learning_rate=0.05,\n",
        "        num_leaves=31,\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_jobs=-1\n",
        "    ))\n",
        "])"
      ],
      "metadata": {
        "id": "M5xIzpDAbOVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"Valutazione modello: {name}\")\n",
        "    summary = evaluate_model_cv(model, X_train_val, y_train_val, cv=5)\n",
        "    cv_results[name] = summary\n",
        "\n",
        "# Costruisco un DataFrame riassuntivo “da portfolio”\n",
        "rows = []\n",
        "for name, metrics_dict in cv_results.items():\n",
        "    row = {\"model\": name}\n",
        "    for metric, values in metrics_dict.items():\n",
        "        row[f\"{metric}_mean\"] = values[\"mean\"]\n",
        "        row[f\"{metric}_std\"] = values[\"std\"]\n",
        "    rows.append(row)\n",
        "\n",
        "results_df = pd.DataFrame(rows)\n",
        "results_df = results_df.sort_values(\"roc_auc_mean\", ascending=False).reset_index(drop=True)\n",
        "results_df.sort_values"
      ],
      "metadata": {
        "id": "XJuUasBFbf0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.3 Confronto modelli\n",
        "\n",
        "La tabella sopra riassume le performance medie in **cross-validation stratificata** (k=5) su Train+Validation.\n",
        "\n",
        "- i modelli **tree-based** (es. Random Forest, XGBoost) hanno una **AUC superiore** rispetto alla Logistic Regression\n",
        "- nel trade-off tra complessità e performance:\n",
        "  - Logistic Regression rimane un **benchmark interpretabile**\n",
        "\n",
        "Nel passo successivo:\n",
        "- selezioneremo uno dei modelli migliori\n",
        "- applicheremo un **tuning iperparametri con Optuna**\n",
        "- valuteremo il modello finale sul **Test Set**."
      ],
      "metadata": {
        "id": "rkPiJU_TcZ71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.4 Hyperparameter Tuning con Optuna (XGBoost)\n",
        "\n",
        "Selezioniamo XGBoost come modello candidato principale e utilizziamo **Optuna** per:\n",
        "\n",
        "- esplorare automaticamente lo spazio degli iperparametri\n",
        "- massimizzare la metrica **ROC AUC** in cross-validation stratificata\n",
        "\n",
        "Il tuning viene effettuato sul blocco **Train+Validation** (`X_train_val`, `y_train_val`), mantenendo il **Test Set** completamente separato.\n"
      ],
      "metadata": {
        "id": "Bj7m-uPzc2Kg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    # spazio di ricerca iperparametri XGBoost\n",
        "    params = {\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 600),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 8),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
        "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1.0, 10.0),\n",
        "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
        "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 10.0, log=True),\n",
        "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-3, 10.0, log=True),\n",
        "    }\n",
        "\n",
        "    model = Pipeline(steps=[\n",
        "        (\"preprocess\", preprocessor),\n",
        "        (\"model\", xgb.XGBClassifier(\n",
        "            objective=\"binary:logistic\",\n",
        "            eval_metric=\"logloss\",\n",
        "            random_state=RANDOM_STATE,\n",
        "            n_jobs=-1,\n",
        "            **params\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "    skf = StratifiedKFold(\n",
        "        n_splits=3,\n",
        "        shuffle=True,\n",
        "        random_state=RANDOM_STATE\n",
        "    )\n",
        "\n",
        "    # cross-validation su ROC AUC\n",
        "    scores = cross_val_score(\n",
        "        model,\n",
        "        X_train_val,\n",
        "        y_train_val,\n",
        "        cv=skf,\n",
        "        scoring=\"roc_auc\",\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    return scores.mean()"
      ],
      "metadata": {
        "id": "mBkpoRVScywr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=150, show_progress_bar=True)\n",
        "\n",
        "print(\"Best ROC AUC:\", study.best_value)\n",
        "print(\"Best params:\")\n",
        "study.best_params"
      ],
      "metadata": {
        "id": "W62SeiiWdFI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.5 Modello finale XGBoost\n",
        "\n",
        "Utilizziamo ora i **migliori iperparametri** trovati da Optuna per:\n",
        "\n",
        "1. ricostruire la pipeline `preprocess + XGBoost`\n",
        "2. addestrare il modello finale su **Train+Validation** (80% dei dati)\n",
        "3. mantenere il **Test Set** come stima out-of-sample.\n"
      ],
      "metadata": {
        "id": "76GSXx2qhthD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_xgb = Pipeline(steps=[\n",
        "    (\"preprocess\", preprocessor),\n",
        "    (\"model\", xgb.XGBClassifier(\n",
        "        objective=\"binary:logistic\",\n",
        "        eval_metric=\"logloss\",\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_jobs=-1,\n",
        "        **study.best_params\n",
        "    ))\n",
        "])\n",
        "\n",
        "best_xgb.fit(X_train_val, y_train_val)\n"
      ],
      "metadata": {
        "id": "Du2-pIDJhuKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Valutazione Finale su Test Set\n",
        "\n",
        "Valutiamo ora il modello finale su dati mai visti (`X_test`, `y_test`):\n",
        "\n",
        "- metriche di classificazione standard (Accuracy, Precision, Recall, F1, AUC)\n",
        "- **Confusion Matrix**\n",
        "- curve **ROC** e **Precision-Recall**\n",
        "- analisi di **tuning della soglia di decisione** per ottimizzare il trade-off tra:\n",
        "  - individuare il maggior numero possibile di **Bad Payers** (alta Recall)\n",
        "  - contenere il numero di **falsi allarmi** (alta Precision).\n"
      ],
      "metadata": {
        "id": "DZhKJSw2h2Zv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predizioni su Test\n",
        "y_test_proba = best_xgb.predict_proba(X_test)[:, 1]\n",
        "y_test_pred = (y_test_proba >= 0.5).astype(int)  # soglia standard 0.5\n",
        "\n",
        "print_classification_metrics(y_test, y_test_pred, y_test_proba, prefix=\"XGBoost Finale - Test (threshold=0.5)\")"
      ],
      "metadata": {
        "id": "jce7JdMJh0TZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_test_pred, labels=[0,1])\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[\"Pred Good (0)\", \"Pred Bad (1)\"],\n",
        "            yticklabels=[\"True Good (0)\", \"True Bad (1)\"])\n",
        "plt.show()\n",
        "\n",
        "print(\"TN:\", tn, \"FP:\", fp, \"FN:\", fn, \"TP:\", tp)\n"
      ],
      "metadata": {
        "id": "7XqhcCgYis_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC Curve\n",
        "RocCurveDisplay.from_predictions(y_test, y_test_proba)\n",
        "plt.title(\"ROC Curve - Test\")\n",
        "plt.show()\n",
        "\n",
        "# Precision-Recall Curve\n",
        "PrecisionRecallDisplay.from_predictions(y_test, y_test_proba)\n",
        "plt.title(\"Precision-Recall Curve - Test\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RZzN5i3WkF3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.1 Threshold Tuning\n",
        "\n",
        "La soglia standard di 0.5 non è necessariamente ottimale in un problema di **credit risk**.\n",
        "\n",
        "Tipicamente:\n",
        "\n",
        "- le banche preferiscono **non perdere Bad Payers** (alta Recall sulla classe 1)\n",
        "- sono disposte a tollerare qualche **falso positivo** in più (clienti buoni classificati come rischiosi)\n",
        "\n",
        "Analizziamo quindi le metriche al variare della soglia di decisione."
      ],
      "metadata": {
        "id": "7D8QV0rQklRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thresholds = np.linspace(0.1, 0.9, 17)  # da 0.1 a 0.9 step 0.05\n",
        "records = []\n",
        "\n",
        "for thr in thresholds:\n",
        "    y_thr = (y_test_proba >= thr).astype(int)\n",
        "    records.append({\n",
        "        \"threshold\": thr,\n",
        "        \"accuracy\": accuracy_score(y_test, y_thr),\n",
        "        \"precision\": precision_score(y_test, y_thr, zero_division=0),\n",
        "        \"recall\": recall_score(y_test, y_thr),\n",
        "        \"f1\": f1_score(y_test, y_thr),\n",
        "    })\n",
        "\n",
        "thr_df = pd.DataFrame(records)\n",
        "thr_df\n"
      ],
      "metadata": {
        "id": "udLNc36BkRBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(thr_df[\"threshold\"], thr_df[\"precision\"], marker=\"o\", label=\"Precision\")\n",
        "plt.plot(thr_df[\"threshold\"], thr_df[\"recall\"], marker=\"o\", label=\"Recall\")\n",
        "plt.plot(thr_df[\"threshold\"], thr_df[\"f1\"], marker=\"o\", label=\"F1-score\")\n",
        "plt.xlabel(\"Threshold\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Metriche al variare della soglia di decisione\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "C66erwnekxsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Explainability (XAI) & Risk Governance\n",
        "\n",
        "I modelli di credit scoring devono essere **interpretabili**:\n",
        "\n",
        "- per ragioni normative (Basilea / EBA Guidelines)\n",
        "- per supportare i **credit officer**\n",
        "- per garantire trasparenza verso i clienti (“adverse action notice”)\n",
        "\n",
        "In questa sezione forniamo spiegazioni **globali** e **locali** del modello finale XGBoost."
      ],
      "metadata": {
        "id": "coARLosYlODm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Estrazione del modello \"puro\" dal pipeline\n",
        "xgb_model = best_xgb.named_steps[\"model\"]\n",
        "\n",
        "# Bisogna anche estrarre i nomi delle feature dopo one-hot encoding\n",
        "preprocessor_fitted = best_xgb.named_steps[\"preprocess\"]\n",
        "\n",
        "# Recuperiamo nomi numerici\n",
        "num_feats = numeric_features.copy()\n",
        "\n",
        "# Recuperiamo nomi categorici (one-hot)\n",
        "ohe = preprocessor_fitted.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
        "cat_feats = ohe.get_feature_names_out(categorical_features).tolist()\n",
        "\n",
        "# Feature names finale\n",
        "feature_names = num_feats + cat_feats\n",
        "\n",
        "# Importance\n",
        "importances = xgb_model.feature_importances_\n",
        "\n",
        "fi_df = pd.DataFrame({\n",
        "    \"feature\": feature_names,\n",
        "    \"importance\": importances\n",
        "}).sort_values(\"importance\", ascending=False).head(20)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(data=fi_df, x=\"importance\", y=\"feature\")\n",
        "plt.title(\" Feature Importances (XGBoost)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "e8FseeallMWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.2 SHAP Values (global & local)\n",
        "\n",
        "SHAP permette di:\n",
        "\n",
        "- spiegare il contributo di ciascuna feature\n",
        "- sia a livello **globale** (summary plot)\n",
        "- sia a livello **individuale** (waterfall plot)\n",
        "\n",
        "Nel contesto creditizio:\n",
        "- valori SHAP positivi aumentano la stima di **rischio (Bad)**\n",
        "- valori SHAP negativi spingono verso **Good**."
      ],
      "metadata": {
        "id": "FdHZ2lnyligO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap.initjs()\n",
        "\n",
        "# Trasformazione del test set tramite preprocessing\n",
        "X_test_trans = preprocessor_fitted.transform(X_test)\n",
        "\n",
        "# SHAP explainer basato su XGBoost\n",
        "explainer = shap.TreeExplainer(xgb_model)\n",
        "shap_values = explainer.shap_values(X_test_trans)\n"
      ],
      "metadata": {
        "id": "UhxU1VGtli5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.summary_plot(shap_values, X_test_trans, feature_names=feature_names)\n"
      ],
      "metadata": {
        "id": "fPpRq1R6l26Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.4 LIME (Local Interpretable Model-agnostic Explanations)\n",
        "\n",
        "LIME genera una spiegazione locale simulando il comportamento del modello\n",
        "attorno ad un punto specifico.\n",
        "\n",
        "È utile come:\n",
        "- strumento didattico\n",
        "- spiegazione leggibile da **analisti di rischio** e stakeholder meno tecnici"
      ],
      "metadata": {
        "id": "pc1MNtiznB6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trasformazione train set\n",
        "X_train_trans = preprocessor_fitted.transform(X_train)\n",
        "\n",
        "# Creazione explainer LIME\n",
        "explainer_lime = LimeTabularExplainer(\n",
        "    training_data=X_train_trans.toarray() if hasattr(X_train_trans, \"toarray\") else X_train_trans,\n",
        "    feature_names=feature_names,\n",
        "    class_names=[\"Good\", \"Bad\"],\n",
        "    discretize_continuous=True\n",
        ")\n",
        "\n",
        "idx = 1\n",
        "\n",
        "# Spiegazione sullo stesso individuo SHAP (idx)\n",
        "x_instance_lime = X_test_trans[idx].toarray()[0] if hasattr(X_test_trans, \"toarray\") else X_test_trans[idx]\n",
        "\n",
        "exp = explainer_lime.explain_instance(\n",
        "    data_row=x_instance_lime,\n",
        "    predict_fn=xgb_model.predict_proba,\n",
        "    num_features=20\n",
        ")\n",
        "\n",
        "exp.show_in_notebook(show_table=True)"
      ],
      "metadata": {
        "id": "dzkzqjUvnDnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.5 Partial Dependence Plots (PDP) & ICE Plots\n",
        "\n",
        "I PDP e ICE consentono di analizzare l'effetto di **una singola feature**\n",
        "sulla probabilità di default, mantenendo fisse le altre variabili.\n",
        "\n",
        "Lettura tipica:\n",
        "- un PDP crescente suggerisce che feature ↑ ⇒ rischio ↑  \n",
        "- un PDP decrescente suggerisce che feature ↑ ⇒ rischio ↓  \n",
        "\n",
        "Gli ICE mostrano come **singoli individui** si comportano rispetto alla media."
      ],
      "metadata": {
        "id": "Knv5tInNnVz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scegli una feature numerica rilevante\n",
        "target_feature = numeric_features[0]  # esempio: \"duration\"\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6,4))\n",
        "PartialDependenceDisplay.from_estimator(\n",
        "    best_xgb,\n",
        "    X_test,\n",
        "    features=[target_feature],\n",
        "    ax=ax\n",
        ")\n",
        "plt.title(f\"PDP per {target_feature}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nbfhl894nWfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(6,4))\n",
        "PartialDependenceDisplay.from_estimator(\n",
        "    best_xgb,\n",
        "    X_test,\n",
        "    features=[target_feature],\n",
        "    kind=\"individual\",   # ICE\n",
        "    ax=ax\n",
        ")\n",
        "plt.title(f\"ICE Plot per {target_feature}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ivij6iHknYW_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}